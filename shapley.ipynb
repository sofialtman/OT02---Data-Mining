{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Optional, List, Callable, Any, Union, Dict\n",
    "from itertools import product\n",
    "from statistics import mean\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterios = 'absolute_error'\n",
    "n_arvores = 400\n",
    "n_atributos =  1/3 #max_features\n",
    "max_niveis = 6\n",
    "\n",
    "\n",
    "resultadosCenario2 = []\n",
    "contagem =1\n",
    "\n",
    "X = df_cleaned.drop('Mortalidade da população infectada(%)', axis=1)\n",
    "y = df_cleaned['Mortalidade da população infectada(%)']\n",
    "\n",
    "  #Normalizando os dados\n",
    "scaler = StandardScaler()\n",
    "X_normalized = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "  #Dividindo em treinamento e teste (com sorteio do tamanho do teste e treinamento)\n",
    "#tam_teste = random.uniform(0.2, 0.3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y ,test_size=0.2, random_state=42)\n",
    "\n",
    "  # Inicializar e treinar o modelo RF\n",
    "rf = RandomForestRegressor(n_estimators=n_arvores, criterion=criterios, max_depth=max_niveis, max_features=n_atributos)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "  # Fazer previsões\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "  # Calcular métricas de avaliação\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape= mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(rmse,mae, mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature_importances_random_forest(random_forest_model):\n",
    "\n",
    "    '''\n",
    "    Prints the feature importances of a Random Forest model in an ordered way.\n",
    "    random_forest_model -> The sklearn.ensemble.RandomForestRegressor or RandomForestClassifier trained model\n",
    "    '''\n",
    "\n",
    "    # Fetch the feature importances and feature names\n",
    "    importances = random_forest_model.feature_importances_\n",
    "    features = random_forest_model.feature_names_in_\n",
    "\n",
    "    # Organize them in a dictionary\n",
    "    feature_importances = {fea: imp for imp, fea in zip(importances, features)}\n",
    "\n",
    "    # Sorts the dictionary\n",
    "    feature_importances = {k: v for k, v in sorted(feature_importances.items(), key=lambda item: item[1], reverse = True)}\n",
    "\n",
    "    # Prints the feature importances\n",
    "    for k, v in feature_importances.items():\n",
    "        print(f\"{k} -> {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_feature_importances_random_forest(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature_importances_shap_values(shap_values, features):\n",
    "\n",
    "    '''\n",
    "    Prints the feature importances based on SHAP values in an ordered way\n",
    "    shap_values -> The SHAP values calculated from a shap.Explainer object\n",
    "    features -> The name of the features, on the order presented to the explainer\n",
    "    '''\n",
    "\n",
    "    # Calculates the feature importance (mean absolute shap value) for each feature\n",
    "    importances = []\n",
    "    for i in range(shap_values.values.shape[1]):\n",
    "        importances.append(np.mean(np.abs(shap_values.values[:, i])))\n",
    "\n",
    "    # Calculates the normalized version\n",
    "    importances_norm = softmax(importances)\n",
    "\n",
    "    # Organize the importances and columns in a dictionary\n",
    "    feature_importances = {fea: imp for imp, fea in zip(importances, features)}\n",
    "    feature_importances_norm = {fea: imp for imp, fea in zip(importances_norm, features)}\n",
    "\n",
    "    # Sorts the dictionary\n",
    "    feature_importances = {k: v for k, v in sorted(feature_importances.items(), key=lambda item: item[1], reverse = True)}\n",
    "    feature_importances_norm= {k: v for k, v in sorted(feature_importances_norm.items(), key=lambda item: item[1], reverse = True)}\n",
    "\n",
    "    # Prints the feature importances\n",
    "    for k, v in feature_importances.items():\n",
    "        print(f\"{k} -> {v:.4f} (softmax = {feature_importances_norm[k]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_feature_importances_shap_values(shap_values,X.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
